<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Deep Learning | Classical approaches to Machine Learning</title>
  <meta name="description" content="Course materials for Classical approaches to Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Deep Learning | Classical approaches to Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figures/cover_image.png" />
  <meta property="og:description" content="Course materials for Classical approaches to Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Deep Learning | Classical approaches to Machine Learning" />
  
  <meta name="twitter:description" content="Course materials for Classical approaches to Machine Learning" />
  <meta name="twitter:image" content="figures/cover_image.png" />

<meta name="author" content="Chris Penfold" />


<meta name="date" content="2022-10-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="solutions-logistic-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About the course</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i><b>1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i><b>1.2</b> Schedule</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#github"><i class="fa fa-check"></i><b>1.3</b> Github</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.4</b> License</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#contact"><i class="fa fa-check"></i><b>1.5</b> Contact</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#colophon"><i class="fa fa-check"></i><b>1.6</b> Colophon</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#installation"><i class="fa fa-check"></i><b>2.1</b> Installation</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#course-materials"><i class="fa fa-check"></i><b>2.2</b> Course materials</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>3</b> Linear regression and logistic regression</a><ul>
<li class="chapter" data-level="3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#regression"><i class="fa fa-check"></i><b>3.1</b> Regression</a><ul>
<li class="chapter" data-level="3.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#linear-regression"><i class="fa fa-check"></i><b>3.1.1</b> Linear regression</a></li>
<li class="chapter" data-level="3.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>3.1.2</b> Polynomial regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression1"><i class="fa fa-check"></i><b>3.2</b> Logistic regression</a></li>
<li class="chapter" data-level="3.3" data-path="logistic-regression.html"><a href="logistic-regression.html#regression-for-spatial-transcriptomics"><i class="fa fa-check"></i><b>3.3</b> Regression for spatial transcriptomics</a></li>
<li class="chapter" data-level="3.4" data-path="logistic-regression.html"><a href="logistic-regression.html#resources"><i class="fa fa-check"></i><b>3.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mlnn.html"><a href="mlnn.html"><i class="fa fa-check"></i><b>4</b> Deep Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="mlnn.html"><a href="mlnn.html#multilayer-neural-networks"><i class="fa fa-check"></i><b>4.1</b> Multilayer Neural Networks</a><ul>
<li class="chapter" data-level="4.1.1" data-path="mlnn.html"><a href="mlnn.html#regression-with-keras"><i class="fa fa-check"></i><b>4.1.1</b> Regression with Keras</a></li>
<li class="chapter" data-level="4.1.2" data-path="mlnn.html"><a href="mlnn.html#image-classification-with-rick-and-morty"><i class="fa fa-check"></i><b>4.1.2</b> Image classification with Rick and Morty</a></li>
<li class="chapter" data-level="4.1.3" data-path="mlnn.html"><a href="mlnn.html#rick-and-morty-classifier-using-deep-learning"><i class="fa fa-check"></i><b>4.1.3</b> Rick and Morty classifier using Deep Learning</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="mlnn.html"><a href="mlnn.html#convolutional-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Convolutional neural networks</a><ul>
<li class="chapter" data-level="4.2.1" data-path="mlnn.html"><a href="mlnn.html#checking-the-models"><i class="fa fa-check"></i><b>4.2.1</b> Checking the models</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="mlnn.html"><a href="mlnn.html#multiclass-cnn"><i class="fa fa-check"></i><b>4.3</b> Multiclass CNN</a></li>
<li class="chapter" data-level="4.4" data-path="mlnn.html"><a href="mlnn.html#categorical-cnn"><i class="fa fa-check"></i><b>4.4</b> Categorical CNN</a><ul>
<li class="chapter" data-level="4.4.1" data-path="mlnn.html"><a href="mlnn.html#intepreting-cnn"><i class="fa fa-check"></i><b>4.4.1</b> Intepreting CNN</a></li>
<li class="chapter" data-level="4.4.2" data-path="mlnn.html"><a href="mlnn.html#class-activation"><i class="fa fa-check"></i><b>4.4.2</b> Class activation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="mlnn.html"><a href="mlnn.html#cnns-for-motif-analysis"><i class="fa fa-check"></i><b>4.5</b> CNNs for Motif analysis</a></li>
<li class="chapter" data-level="4.6" data-path="mlnn.html"><a href="mlnn.html#data-augmentation"><i class="fa fa-check"></i><b>4.6</b> Data augmentation</a><ul>
<li class="chapter" data-level="4.6.1" data-path="mlnn.html"><a href="mlnn.html#transfer-learning"><i class="fa fa-check"></i><b>4.6.1</b> Transfer learning</a></li>
<li class="chapter" data-level="4.6.2" data-path="mlnn.html"><a href="mlnn.html#more-complex-networks"><i class="fa fa-check"></i><b>4.6.2</b> More complex networks</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="mlnn.html"><a href="mlnn.html#autoencoders"><i class="fa fa-check"></i><b>4.7</b> Autoencoders</a></li>
<li class="chapter" data-level="4.8" data-path="mlnn.html"><a href="mlnn.html#further-reading"><i class="fa fa-check"></i><b>4.8</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="solutions-logistic-regression.html"><a href="solutions-logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Solutions to Chapter 4 - Linear regression and logistic regression</a></li>
<li class="chapter" data-level="6" data-path="solutions-nnet.html"><a href="solutions-nnet.html"><i class="fa fa-check"></i><b>6</b> Solutions to Chapter 5 - Neural Networks</a></li>
<li class="chapter" data-level="7" data-path="gaussian-process-regression.html"><a href="gaussian-process-regression.html"><i class="fa fa-check"></i><b>7</b> Gaussian process regression</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Classical approaches to Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mlnn" class="section level1">
<h1><span class="header-section-number">4</span> Deep Learning</h1>
<!-- Chris -->
<div id="multilayer-neural-networks" class="section level2">
<h2><span class="header-section-number">4.1</span> Multilayer Neural Networks</h2>
<p>Neural networks are increasingly used to address a variety of complex problems in biology under the umbrella of <em>deep learning</em>. This umbrella contains a diverse range of techniques, tools, and heursitics, that have collectively been used to address everything from image analysis <span class="citation">(Chamier et al. <a href="#ref-von2021democratising">2021</a>)</span> to the data avalanch of modern genomics <span class="citation">(Angermueller and Stegle <a href="#ref-angermueller2016deep">2016</a>,<span class="citation">Mohammad Lotfollahi (<a href="#ref-Mohammad2019deep">2019</a>)</span>,<span class="citation">Zhang et al. (<a href="#ref-zhang2022assessing">2022</a>)</span>)</span>; from protein structure prerdiction <span class="citation">(Jumper et al. <a href="#ref-jumper2021highly">2021</a>)</span> to drug perrturbation prediction and discovery <span class="citation">(Gómez-Bombarelli et al. <a href="#ref-gomez2018automatic">2018</a>,<span class="citation">Rampášek et al. (<a href="#ref-rampavsek2019dr">2019</a>)</span>)</span>. These techniques include densely connected networks, convolutional neural networks (CNN), autoencoders (AE), and adversarial neural networks (ANN), as well as more recent developments such as diffusion models.</p>
<p>In this chapter we will explore some of the basics of <em>deep learning</em> on a practical level. We will first learn how to construct a simple densly connected neural networks within R using {keras}, and use these networks for regression. Later we will try our hand at image classification using a set of images taken from the animated TV series <a href="https://en.wikipedia.org/wiki/Rick_and_Morty">Rick and Morty</a>. For those unfamiliar with Rick and Morty, the series revolves around the adventures of Rick Sanchez, an alcoholic scientist, and his neurotic grandson, Morty Smith. Although many scientists aspire to be like Rick, they're usually more of a Jerry. Our motivating goal in the latter sections will be to develop an image classification algorithm capable of telling if any given image contains Rick or not. Finally, we will adapt these techniques to identify DNA motifs from ChIP-sequencing data.</p>
<p>The main take home message from this section are:</p>
<ol style="list-style-type: decimal">
<li>It's important to look at the data.</li>
<li>It's probably just as important to have a clear question in mind. A clear question should precede the data generation (or data assembly) step.</li>
<li>There are a limitless variety of architectures that can be built into a neural networks. Picking one to use is often arbitrary or <em>at best</em> empirically-motivated by previous works. Having a clear idea of the limitations of the data and having a clear question can help pin this down.</li>
<li>Some apprroaches and architectures are particularly suited to specific tasks.</li>
</ol>
<div id="regression-with-keras" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Regression with Keras</h3>
<p>We will first build a multilayer densely connected Neural Network (NN) to perform regression. A user friendly package for <em>neural networks</em> is available via <a href="https://keras.io">keras</a>, an application programming interface (API) written in Python, which uses <a href="https://www.tensorflow.org">tensorflow</a> as a back-end. An R interface for keras is available in the form of <a href="https://keras.rstudio.com/">keras/tensorflow for R</a>. We will first install (or import) the relevant packages (see section 3 for further details about installation or follow the installation instructions <a href="https://tensorflow.rstudio.com/install/https://tensorflow.rstudio.com/install/">here</a>). In my case, I have installed Tensorflow within Python3.9, and can set R to call this version using reticulate. We will also load a few other packages for general plotting and data manipulation.</p>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre><code>## Warning: package &#39;jpeg&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Warning: package &#39;reticulate&#39; was built under R version 3.5.2</code></pre>
<p>The task of building -- and using -- a densly connected neural network moreorless follows the same recipe as for other ML models:</p>
<ol style="list-style-type: decimal">
<li>We first generate or assemble an appropriate dataset, which will be split into training/test/validation sets.</li>
<li>We next pick an appropriate method to address a specific question. This consists of choosing a particular architecture, initialising some parameters, and setting others.</li>
<li>Finally, we pick an appropriate objective function we wish to optimise with respect to the parameters of the model.</li>
<li>Once optimised, we can use the model to make predictions or use the results to intepret aspects of the system we're studying.</li>
</ol>
<p>As a motivvating example, we first aim to build a neural network to approximate the square root of a number. We will have to generate a synthetic dataset: for the training set we generate two arrays, an <em>input</em> array, containing a random set of numbers sampled from a given interval (e.g. between <span class="math inline">\(0\)</span> and <span class="math inline">\(100\)</span>), and an <em>output</em> array, containing the square roots of those numbers, which we have numerically calculated. A similar set of data will be independently generated for the validation set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>)

tdims &lt;-<span class="st"> </span><span class="dv">50</span> <span class="co">#Number of samples to generate</span>

<span class="co">#We first generate random locations from an interval for the training set and store them as an array, then numerically calculate the square root at these locations (again storing as an array)</span>
trainingX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>)) <span class="co">#Store data as an array (as required by Keras)</span>
trainingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">runif</span>(tdims, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">100</span>) <span class="co">#Generate random x in range 0 to 100</span>

trainingY  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>))
trainingY[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(trainingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>])

<span class="co">#Now do the same but for a independently generated test set</span>
testingX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>)) <span class="co">#Store as arrays</span>
testingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">runif</span>(tdims, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">100</span>)
testingY  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>))
testingY[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(testingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>])</code></pre></div>
<p>Here we have a 1D (scalar) input, and a 1D (scalar) output, and need to construct a multi-layer neural network to approximate the function that maps form one to the other, in a way that hopefully generalises. Now we need to construct the actual neural network that will do this. Keras has an simple and intuitive way of specifying <a href="https://keras.io/layers/core/">layers</a> of a neural network, and the R wrapper for keras makes good use of this (see [here for documentation]{<a href="https://tensorflow.rstudio.com/" class="uri">https://tensorflow.rstudio.com/</a>}). We first initialise the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</code></pre></div>
<p>This tells keras that we're using the Sequential API i.e., a simple architecture in which the first layer will be connected to the second, the second to the third and so forth, which distinguishes it from more complex networks possible using the Model API. Once we've specified this sequential model, we can start adding layers to the neural network one by one.</p>
<p>When specifying the first layer of the network, we must also include the dimension of the input data. A standard layer of neurons, can be specified using the {layer_dense} function. When adding a layer we also need to specify the activation function to the next level. This can be done via {activation}. Early on step functions annd sigmoid activation funnctions were common, but were gradually replaced by relu activations, mostly for empircal performence reasons. So to add a layer of <span class="math inline">\(100\)</span> nodes with a Rectified Linear Unit (relu) activation, our code would look something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>),<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>)</code></pre></div>
<p>This represets our first hidden layer. The various parameters of the model, such as the weights of the individual connections and biases, will be initialised by default, although if we were interested we could select from a number of differe schemes manually or even encode our own custom initialisation. In the default setting, the connection weights are initialised as a uniform random variables over a particular range, with the biases set to zero.</p>
<p>We could add a second hidden layer of <span class="math inline">\(120\)</span> neurons (with relu activation and randomly initialised parameters), so that our code would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>), <span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>)</code></pre></div>
<p>Finally, we add the output neuron(s). The number of output neurons depends on our task: it should match the size of the output we're aiming to predict. In this section we have just one output, a scalar representing the square root of the input, so will have a {layer_dense(1)} output. Unlike the earlier layers, the final activation function will depend on the nature of our data, and should be appropriately set according to the task. If, for example, we're doing regression, in which the output variable could feasibly take any real valued number, it would be inappropriate to set a sigmoid activation, which would constrain our possible inference to lie between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. Instead we might instead specify a {linear} activation function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>),<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;linear&quot;</span>)</code></pre></div>
<p>That's it. Simple! Our model is now complete; we have specified a multi-layered neural network for regression consisting of two hidden layers of width <span class="math inline">\(100\)</span> and <span class="math inline">\(120\)</span> respectively. We can print a summary of the network, to visualise how many parameters it has via:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<p>In total, this model contans <span class="math inline">\(12,441\)</span> parameters, many more parameters than we're used to for other machine learning models. However, in terms of size and number of parameters, this is a tiny model: some of the bigger models out there have already surpassed <a href="https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/"><span class="math inline">\(500\)</span> billion parameters</a>.</p>
<p>Before we use our model to perform inference, we must first compile it. In this case we need to specify three things:</p>
<ul>
<li><p>A <a href="https://keras.io/losses/">loss</a> function, which specifies the objective function that the we will try to minimise with respect to these <span class="math inline">\(12,441\)</span> parameters. A number of existing loss functions are built into keras, including the mean squared error (mean_squared_error) for regression, binary cross entrophy for binary classification (binary_crossentropy), and categorical cross entropy (categorical_crossentropy), which is used for categorical classification. Since we are dealing with regression, we will stick with the mean squared error.</p></li>
<li><p>An <a href="https://keras.io/optimizers/">optimiser</a>, which determines how the loss function is optimised. Possible examples include stochastic gradient descent ({sgd}), root mean square propagation ({rmsprop}), and Adam ({adam}). We will generally use Adam within this chapter.</p></li>
<li><p>A list of <a href="https://keras.io/metrics/">metrics</a> to return. These do not directly impact the optimisation, but are additional summary statistics that keras evaluates and prints out, which can come in very handy when intepreting or summarising the results. For classification, a good choice would be accuracy ({binary_accuracy} or {categorical_accuracy}) whilst for regression we could print out various metrics including the root mean square error, mean absolute error, and so forth.</p></li>
</ul>
<p>We compile our model using {compile}:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)</code></pre></div>
<p>Finally the model is fitted to the data. When doing so we should additionally specify the validation set (if we have one), the batch size, and the number of epochs. Recall batch size is the number of training examples we draw at once for one forward/backward pass, and one epoch is one forward pass and one backward pass through all batches that constitute the complete training dataset. Our complete code would then look like the sippet below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>),<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;linear&quot;</span>)</code></pre></div>
<pre><code>## Loaded Tensorflow version 2.7.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainingX, <span class="dt">y =</span> trainingY, <span class="dt">validation_data =</span> <span class="kw">list</span>(testingX, testingY), <span class="dt">epochs =</span> <span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">2</span>)</code></pre></div>
<p>Alternatively to above, rather than specify the training and validation data sets manually, we could use validation_split to specify the fraction of data to be used as the validation set. This can be useful when dealing with larger datasets. Generally in this section we have very small datasets and can load all the input and output data into memory, but may not be possible if dealing with images or large genomic data. Instead we could specify validation_split along with flow_from_directory to read small batches directly from a directory.</p>
<p>We can see that the mean square error rapidly decreases (from approx. 16 at epoch 3 to around 0.8 towards the end). Precicesly how the objective funciton is optimised is based on back propogation (you can read more on this <a href="https://towardsdatascience.com/understanding-backpropagation-algorithm-7bb3aa2f95fd">here</a>, <a href="https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8">here</a>, and <a href="https://medium.com/spidernitt/breaking-down-neural-networks-an-intuitive-approach-to-backpropagation-3b2ff958794c">here</a>). As always, let's take a look at the actual results, rather than rely on summary metrics. To make predictions using the model we can use the {predict} function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xstar &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">200</span>,<span class="dt">by=</span><span class="fl">0.5</span>)
forecastY &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(xstar)
<span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>forecastY ), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span><span class="kw">sqrt</span>(xstar)), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Okay, so it's not particularly good. However, we didn't use a large training set and there are a few things we can do to try to optimise the network. Another important point is that we didn't use the <em>best</em> network for prediction (the one with the best validation set error). By default when we call prediction functions we tend to use whatever the final network was during our training: if we ran for <span class="math inline">\(10\)</span> epochs, it would be the network we had at the end of epoch <span class="math inline">\(10\)</span>. We can add a callback to save the best model, which would then look something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>),<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;linear&quot;</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/densemodel.h5&#39;</span>, <span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_mse&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)


tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainingX, <span class="dt">y =</span> trainingY, <span class="dt">validation_data =</span> <span class="kw">list</span>(testingX, testingY), <span class="dt">epochs =</span> <span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">0</span>,  <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>This optimised model can be loaded in and used for prediction:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/densemodel.h5&#39;</span>)
xstar &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">200</span>,<span class="dt">by=</span><span class="fl">0.5</span>)
forecastY &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(xstar)
<span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>forecastY ), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span><span class="kw">sqrt</span>(xstar)), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We can try varying a few other aspects of the network to get an idea of how NNs behave. For example, first try increasing the training set size. Try adding or removing layers, and varying layer widths. Another thing thing that can be varied is the final layer activation. The <a href="https://keras.io/api/layers/activations/">keras manual</a> should provide a useful resource to explore what options are available.</p>
<p>In the snippet of code below we use a comparatively large dataset, with the input data generated in the region <span class="math inline">\([0,80]\)</span> and <span class="math inline">\([120,200]\)</span>. By ensuring there is no input data generated in the range <span class="math inline">\((80,120)\)</span> it is much easier to see if the moodel is extrapolating over locations with no data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tdims &lt;-<span class="st"> </span><span class="dv">5000</span> <span class="co">#Number of samples to generate</span>

trainingX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>)) <span class="co">#Store data as an array (required by Keras)</span>
trainingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st">  </span><span class="kw">c</span>( <span class="kw">runif</span>(tdims<span class="op">/</span><span class="dv">2</span>, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">80</span>),  <span class="kw">runif</span>(tdims<span class="op">/</span><span class="dv">2</span>, <span class="dt">min=</span><span class="dv">120</span>, <span class="dt">max=</span><span class="dv">200</span>) )
trainingY  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>))
trainingY[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(trainingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>])

<span class="co">#Now do the same but for a independently generated test set</span>
testingX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>)) <span class="co">#Store as arrays</span>
testingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">runif</span>(tdims, <span class="dt">min=</span><span class="dv">0</span>, <span class="dt">max=</span><span class="dv">200</span>)
testingY  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(tdims,<span class="dv">1</span>))
testingY[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(testingX[<span class="dv">1</span><span class="op">:</span>tdims,<span class="dv">1</span>])


model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">10</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">20</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;linear&quot;</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;mse&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/densemodel.h5&#39;</span>, <span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_mse&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)


tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainingX, <span class="dt">y =</span> trainingY, <span class="dt">validation_data =</span> <span class="kw">list</span>(testingX, testingY), <span class="dt">epochs =</span> <span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">0</span>,  <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))

model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/densemodel.h5&#39;</span>)
xstar &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">250</span>,<span class="dt">by=</span><span class="fl">0.5</span>)

forecastY &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(xstar)

dataLM &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>trainingX,<span class="dt">y=</span>trainingY)
lrfit &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> dataLM, y<span class="op">~</span>x)
predictedValues&lt;-<span class="kw">predict.lm</span>(lrfit, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar) )

<span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>forecastY ), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>predictedValues), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;green&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span><span class="kw">sqrt</span>(xstar)), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Let's take a closer look over the range where we didn't have any training data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/densemodel.h5&#39;</span>)
xstar &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">60</span>,<span class="dv">140</span>,<span class="dt">by=</span><span class="fl">0.5</span>)

forecastY &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(xstar)

dataLM &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>trainingX,<span class="dt">y=</span>trainingY)
lrfit &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> dataLM, y<span class="op">~</span>x)
predictedValues&lt;-<span class="kw">predict.lm</span>(lrfit, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar) )

<span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>forecastY ), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span>predictedValues), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span>
<span class="kw">geom_line</span>(<span class="dt">color=</span><span class="st">&#39;green&#39;</span>,<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x=</span>xstar,<span class="dt">y=</span><span class="kw">sqrt</span>(xstar)), <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Not perfect, but better than a linear model, at least. So we have a model that has interpolated reasonably well. These types of models are pretty good at inference for a whole range of real world (nonlinear) functions for which there is a sufficient amount of data.</p>
<p>Excercise 2.1: How could you modify the above code for inferece in a system where we have <span class="math inline">\(5\)</span> input variables and <span class="math inline">\(3\)</span> output variables?</p>
</div>
<div id="image-classification-with-rick-and-morty" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Image classification with Rick and Morty</h3>
<p>We will now try to modify our network for image classification. As with any machine learning application, it's important to have both a question in mind (in this case &quot;can we identify images that contain Rick Sanchez&quot;), and understand the dataset(s) we're using. For training purposes I have downloaded several thousand random images of Rick Sanchez and several thousand images without Rick from the website <a href="https://masterofallscience.com">Master of All Science</a>. The image data can be found in the directory {data/RickandMorty/data/}, which we can load and plot using the {readJPEG} and {grid.raster} functions respectively.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">im &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="st">&quot;data/RickandMorty/altdata/AllRickImages/Rick_1.jpg&quot;</span>)
grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(im, <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>We can use the funciton {dim(im)} to return the image dimensions. In this case each image is stored as a jpeg file, with a <span class="math inline">\(90 \times 160\)</span> pixel resolution with <span class="math inline">\(3\)</span> colour channels (RGB). This loads into R as <span class="math inline">\(160 \times 90 \times 3\)</span> array. We could start by converting the image to grey scale, reducing the dimensions of the input data. However, each channel will potentially carry novel information, so ideally we wish to retain all of the information. You can take a look at what information is present in the different channels by plotting them individually using e.g., {grid.raster(im[,,3], interpolate=FALSE)}. Whilst the difference is not so obvious here, we can imagine sitations where different channels could be dramamtically different, for example, when dealing with remote observation data from satellites, where we might have visible wavelengths alongside infrared and other wavelengths.</p>
<p>Since we plan to retain the channel information, our input data is a tensor of dimension <span class="math inline">\(90 \times 160 \times 3\)</span> i.e., height x width x channels. Note that this ordering is important, as keras expects this ordering (but be careful, as other packages can expect a different ordering).</p>
<p>Before building a neural network we first have to load the data and construct a training, validation, and test set of data. Whilst the package we're using has the ability to specify this on the fly (flow_images_from_directory), for smaller datasets I prefer to manually seperate out training/test/validation sets, as it makes it a little easier debug when things go wrong.</p>
<p>First load all <em>Rick</em> images and all <em>not Rick</em> images from their directory. We can get a list of all the <em>Rick</em> and <em>not Rick</em> images using {list.files}:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">files1 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/altdata/AllRickImages/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>)
files2 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/altdata/AllMortyImages/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>)</code></pre></div>
<p>After loading the files we can see we have <span class="math inline">\(2211\)</span> images of <em>Rick</em> and <span class="math inline">\(3046\)</span> images of <em>not Rick</em>, for a total of <span class="math inline">\(5257\)</span> imaages. Whilst this is a slight class imbalaance in the dataset (there are more not Rick images than Rick images) it is not dramatically so; in cases where there is extreme imbalance in the number of class observations we may have to do something extra, such as data augmentation, or assinging weights during training.</p>
<p>We next preallocate an empty array to store these training images for the <em>Rick</em> and <em>not Rick</em> images (an array of dimension <span class="math inline">\(5257 \times 90 \times 160 \times 3\)</span>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">allX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2),<span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="kw">dim</span>(im)[<span class="dv">3</span>]))</code></pre></div>
<p>We can load images using the {readJPEG} function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files1)){
  allX[i,<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/altdata/AllRickImages/&quot;</span>, files1[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}</code></pre></div>
<p>Similarly, we can load the <em>not Rick</em> images and store in the same array:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files2)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/altdata/AllMortyImages/&quot;</span>, files2[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}</code></pre></div>
<p>Next we can construct the output variable (usually denoted Y). The nature of this depends on the data itself. In the simplest case we are looking to infer a Rick or not, which is a binary variable, with a zero (<span class="math inline">\(0\)</span>) indicating Rick present, annd one (<span class="math inline">\(1\)</span>) indicating no Rick (we could always flip this assignment round and have a <span class="math inline">\(1\)</span> for Rick it shouldn't make a difference). The output can therefore be represented as a single (binary) output node. We can construct Y as a vector of length <span class="math inline">\(5257\)</span> containing the classification for each of the images e.g., a <span class="math inline">\(0\)</span> if the image is a <em>Rick</em> and <span class="math inline">\(1\)</span> if it is <em>not Rick</em>. This is simple enough using the function {rbind}, as we know the first <span class="math inline">\(2211\)</span> images were <em>Rick</em> (so create a vector of zeros of length 2211) and the second lot of images are <em>not Rick</em> (create a vector of ones of length 3046) and join them together using rbind.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">labels &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">matrix</span>(<span class="dv">0</span>, <span class="kw">length</span>(files1), <span class="dv">1</span>), <span class="co">#These are the Rick laabels</span>
                <span class="kw">matrix</span>(<span class="dv">1</span>, <span class="kw">length</span>(files2), <span class="dv">1</span>)) <span class="co">#These are the not Rick labels</span></code></pre></div>
<p>Next, we must now split our data in training sets, validation sets, and test sets. In fact I have already stored some seperate &quot;test&quot; set images in another folder that we will load in at the end, so here we only need to seperate images into training and validation sets. It's important to note that we shouldn't simply take the first <span class="math inline">\(N\)</span> images for training with the remainder used for validation/testing, since this may introduce artefacts. For example, here we've loaded in all the <em>Rick</em> images in first, with the <em>not Rick</em> images loaded in second: if we took, say, the first <span class="math inline">\(2000\)</span> images for training, we would be training with only Rick images, which makes our task impossible, and our algorithm will fail catastrophically.</p>
<p>Although there are more elegant ways to shuffle data using {keras}, here we are going to randomly permute the data, and then take the first <span class="math inline">\(4000\)</span> permuted images for training, with the remainder for validation (Note: it's crucial to permute the <span class="math inline">\(Y\)</span> data in the same way). This gives us a <span class="math inline">\(76%\)</span> to <span class="math inline">\(24%\)</span> split for training to validation data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>) <span class="co">#Set random number generator for R aspects of the session</span>

vecInd &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)) <span class="co">#A vector of indexes of the length of the data</span>
trainInd &lt;-<span class="st"> </span><span class="kw">sample</span>(vecInd)[<span class="dv">1</span><span class="op">:</span><span class="dv">4001</span>] <span class="co">#Permute and take first 4000 training</span>

<span class="co">#Training set</span>
trainX &lt;-<span class="st"> </span>allX[trainInd, , , ]
trainY &lt;-<span class="st"> </span>labels[trainInd, <span class="dv">1</span>]

<span class="co">#Val set</span>
valX &lt;-<span class="st"> </span>allX[<span class="op">-</span>trainInd, , , ]    
valY &lt;-<span class="st"> </span>labels[<span class="op">-</span>trainInd, <span class="dv">1</span>]</code></pre></div>
<p>We are almost ready to begin building our neural networks. First we can try a few things to make sure our data has been processed correctly. For example, try manually plotting several of the images and seeing if the labels are correct. Manually print out the image matrix (not a visualisation of it): think about the range of the data, and whether it will need normalising. Finally we can check to see how many of each class is in the training and validation datasets (e.g., sum trainY/testY and compare to the length of trainY/testY). In this case there are <span class="math inline">\(1681\)</span> images of <em>Rick</em> and <span class="math inline">\(2320\)</span> images of <em>not Rick</em> in the training dataset. Again, whilst there is some slight class inbalance it is not terrible, so we don't need to perform data augmentation or assign weights to the different classes during training.</p>
</div>
<div id="rick-and-morty-classifier-using-deep-learning" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Rick and Morty classifier using Deep Learning</h3>
<p>Let us return to our example of image classification. We start by specifying a sequential network as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span></code></pre></div>
<p>Our data is slightly different to the usual inputs we've been dealing with: that is, we're not dealing with an input vector, but instead have an array. In this case each image is a <span class="math inline">\(90 \times 160 \time 3\)</span> array. So for our first layer we first have to flatten this down using {flatten}:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>))</code></pre></div>
<p>This should turn our <span class="math inline">\(90 \times \160 \times 3\)</span> input into a <span class="math inline">\(1 \times 43200\)</span> node input. We now add intermediate layers connected to the input layer with rectified linear units ({relu}) as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>)</code></pre></div>
<p>Finally we connect this layer over the final output layer (one neuron) with sigmoid activation: <a href="https://keras.io/activations/">activation</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>) , <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span> ) <span class="op">%&gt;%</span>
<span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">100</span>)</code></pre></div>
<p>The complete model should look something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</code></pre></div>
<p>We can print a summary of the network, for example to see how many parameters it has:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model)</code></pre></div>
<p>In this case we see a total of <span class="math inline">\(4,332,341\)</span> parameters. Yikes, that's a lot of parameters to tune (well not compared some models), and not much data! Next we need to compile and run the model. In this case we need to specify the loss, optimiser, and metrics. Since we are dealing with binary classification, we will use binary cross entropy (binary_crossentropy) and for classification, a good choice of metrics would be {binary_accuracy}. We can compile our model using {keras_compile}:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;binary_accuracy&quot;</span>)</code></pre></div>
<p>Finally the model can be fitted to the data. When doing so we additionally need to specify the validation set (if we have one), the batch size and the number of epochs, where an epoch is one forward pass and one backward pass of all the training examples, and the batch size is the number of training examples in one forward/backward pass. You may want to go and get a tea whilst this is running!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">epochs =</span> <span class="dv">25</span>, <span class="dt">verbose =</span> <span class="dv">2</span>)</code></pre></div>
<p>Together with an added callback to save the best model, our code should look something like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_flatten</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">100</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">120</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;binary_accuracy&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/model_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_binary_accuracy&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)


tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">epochs =</span> <span class="dv">25</span>, <span class="dt">batch_size=</span><span class="dv">500</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>As before we can load a saved model in using the {load_model_hdf5} function and use it for predictions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/model.h5&#39;</span>)</code></pre></div>
<p>For this model we achieved an accuracy of above <span class="math inline">\(0.62\)</span> on the validation dataset at epoch <span class="math inline">\(20\)</span> (which had a corresponding accuracy <span class="math inline">\(0.53\)</span> on the training set). Not fantastic when you consider that given the slight imbalance in the number of images in each class, a niave algorithm that always assigns the data to <em>not Rick</em> would achieve an accuracy of <span class="math inline">\(0.58\)</span> and <span class="math inline">\(0.57\)</span> in the training and validation sets respectively. It seems like we're getting nowhere fast, and need to change tactic.</p>
<p>We need to think a little more about what the data actually <em>is</em>. In this case we're looking at a set of images. As Rick Sanchez can appear almost anywhere in the image, there's no reason to think that a given input node should correspond in two different images to any useful feature, so it's not surprising that the network did so badly, this is simply a task that a densely connected network is poor at. We need something that can extract out features from the image irregardless of where Rick is. There are approaches build precisely for image analysis that do just this: convolutional neural networks (CNN).</p>
</div>
</div>
<div id="convolutional-neural-networks" class="section level2">
<h2><span class="header-section-number">4.2</span> Convolutional neural networks</h2>
<p>Convolutional neural networks essentially scan across an image and extract out a set of feature representations. These features might then be passed on to a deeper layer (either a convolutional layer or other appropriate layer) which extract out higher order features, as shown in Figure <a href="mlnn.html#fig:covnet">4.1</a>. Finally, a densely connected network acts to combine the end features together for prediction, at least in an idealised description of what's going on.</p>
<div class="figure" style="text-align: center"><span id="fig:covnet"></span>
<img src="images/Screen-Shot-2015-11-07-at-7.26.20-AM.png" alt="Example of a multilayer convolutional neural network" width="50%" />
<p class="caption">
Figure 4.1: Example of a multilayer convolutional neural network
</p>
</div>
<p>In keras we can add a 2D convolutional layer using {layer_conv_2d}. A multilayer convolutional neural network might look something like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>))</code></pre></div>
<p>which will construct <span class="math inline">\(20\)</span> feature maps (using a kernel of size <span class="math inline">\(5 \times 5\)</span>). A <span class="math inline">\(2 \times 2\)</span> max-pool layer would then be added to condense down the feature representations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</code></pre></div>
<p>In this case, by default the max-pooling slides one pixel at a time across the image, but we can set the max-pooling to take bigger steps by setting the {strides} option. A complete example model is shown below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_flatten</span>( ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/modelCNN_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_binary_accuracy&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;binary_accuracy&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size=</span><span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>Here we only ran the model for <span class="math inline">\(5\)</span> epochs just to get an feel for it. If we did have time to run this model longer, we would see much better accuracy. We have an accuracy of <span class="math inline">\(0.88\)</span> on the validation dataset at epoch <span class="math inline">\(43\)</span>, with a training accuracy of <span class="math inline">\(0.995\)</span>. Whilst this is still not great (compared to how well a human could do on a similar task), it's accurate enough to begin making predictions and visualising the results. Fortunately I've already run (and saved) this model for <span class="math inline">\(50\)</span> epochs, so let's load it in for predictions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/modelCNN.h5&#39;</span>)</code></pre></div>
<p>We can use this model to make predictions for images not present in either the training or validation datasets. We load in the new set of images, which can be found in the {predictions} subfolder:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">files &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/data/predictions/&quot;</span>,<span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>)
predictX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>,<span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(files),<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>))
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files)){
  x &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/predictions/&quot;</span>, files[i],<span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
  predictX[i,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] &lt;-<span class="st"> </span>x[<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]
}</code></pre></div>
<p>A hard classification can be assigned using the {predict_classes} function, whilst the actual probability of assignment to either class can be evaluated using {predict} (this can be useful for images that might be ambiguous).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">probY &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(predictX) <span class="co">#Probability of it being class 1 i,e., a not Rick (1-this for prob of a Rick)</span>
predictY &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(probY<span class="op">&gt;</span><span class="fl">0.5</span>) <span class="co">#Hard assignment at p=0.5, a 1 if not Rick, and 0 if Rick</span></code></pre></div>
<p>We can plot an example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">choice =<span class="st"> </span><span class="dv">13</span>
grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="cf">if</span> (predictY[choice]<span class="op">==</span><span class="dv">1</span>) {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Not Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">15</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>))
} <span class="cf">else</span> {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">25</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>))
}</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">choice =<span class="st"> </span><span class="dv">1</span>
grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="cf">if</span> (predictY[choice]<span class="op">==</span><span class="dv">1</span>) {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Not Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">25</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>))
} <span class="cf">else</span> {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">15</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>))
}</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">choice =<span class="st"> </span><span class="dv">6</span>
grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="cf">if</span> (predictY[choice]<span class="op">==</span><span class="dv">1</span>) {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Not Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">25</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>))
} <span class="cf">else</span> {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">25</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>))
}</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
choice =<span class="st"> </span><span class="dv">16</span>
<span class="cf">if</span> (predictY[choice]<span class="op">==</span><span class="dv">1</span>) {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Not Rick: Must be a Jerry&#39;</span>,<span class="dt">x =</span> <span class="fl">0.4</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">15</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>))
} <span class="cf">else</span> {
  <span class="kw">grid.raster</span>(predictX[choice,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>)
  <span class="kw">grid.text</span>(<span class="dt">label=</span><span class="st">&#39;Rick&#39;</span>,<span class="dt">x =</span> <span class="fl">0.2</span>, <span class="dt">y =</span> <span class="fl">0.77</span>,<span class="dt">just =</span> <span class="kw">c</span>(<span class="st">&quot;left&quot;</span>, <span class="st">&quot;top&quot;</span>), <span class="dt">gp=</span><span class="kw">gpar</span>(<span class="dt">fontsize=</span><span class="dv">15</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>))
}</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<div id="checking-the-models" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Checking the models</h3>
<p>Although our model seems to be doing reasonably well, it always helps to see where things are going wrong. Let's take a look at a few of the false positives and a few of the false negatives.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">probvalY &lt;-<span class="st">  </span>model <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">predict</span>(valX)
predictvalY &lt;-<span class="kw">as.numeric</span>(probvalY<span class="op">&gt;</span><span class="fl">0.5</span>)

TP &lt;-<span class="st"> </span><span class="kw">which</span>(predictvalY<span class="op">==</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>valY<span class="op">==</span><span class="dv">1</span>)
FN &lt;-<span class="st"> </span><span class="kw">which</span>(predictvalY<span class="op">==</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>valY<span class="op">==</span><span class="dv">1</span>)
TN &lt;-<span class="st"> </span><span class="kw">which</span>(predictvalY<span class="op">==</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>valY<span class="op">==</span><span class="dv">0</span>)
FP &lt;-<span class="st"> </span><span class="kw">which</span>(predictvalY<span class="op">==</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>valY<span class="op">==</span><span class="dv">0</span>)</code></pre></div>
<p>Let's see where we got it right. These were all predicted as not Rick, and the images did not contain a Rick:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[TP[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[TP[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[TP[<span class="dv">3</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>And these were all predicted as Rick and the image contained a Rick:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[TN[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[TN[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[TN[<span class="dv">3</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>And these we got wrong (predicted Rick, but he was't there):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[FN[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[FN[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[FN[<span class="dv">3</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>Or predicted not Rick, but he was in the image:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[FP[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[FP[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[FP[<span class="dv">4</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Whilst visualising the data is often helpful, in this case it's not entirely clear why the network is failing in some of these cases. An alternative way to look at what's going wrong is a look at which pixels are contributing the most to the classifier, as we highligted in the lecture. We will return to this shortly.</p>
</div>
</div>
<div id="multiclass-cnn" class="section level2">
<h2><span class="header-section-number">4.3</span> Multiclass CNN</h2>
<p>In the previous section we dealt with predicting a Rick (0) or a not Rick (1). This is because we framed our goal as a simple binary question: an image either has a Rick in or it doesn't. Given the nature of the data, there are other possible questions we might be interested in: for example, does the image contain another character, such as Morty? A given image could both a Rick and a Morty, one or the other, or neither. We cold therefore frame our interst as two binary questions: &quot;does the image contain a Rick?&quot; and &quot;does the image contain a Morty?&quot; requiring two output nodes. I have already processed the invidual images into seperate folders, one folder containing only Rick, one containing only Morty, one containing both in the same image, and one containing neither. These can be read in:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">files1 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllRickImages/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>) <span class="co">#These contain Rick but not Morty</span>
files2 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllMortyImages/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>) <span class="co">#These contai Morty but not Rick</span>
files3 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/data/ThreeClassModel/Both/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>) <span class="co">#These contain both Rick and Morty</span>
files4 &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="dt">path =</span> <span class="st">&quot;data/RickandMorty/data/ThreeClassModel/Neither/&quot;</span>, <span class="dt">pattern =</span> <span class="st">&quot;jpg&quot;</span>) <span class="co">#These contain neither</span>

allX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)<span class="op">+</span><span class="kw">length</span>(files3)<span class="op">+</span><span class="kw">length</span>(files4),<span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="kw">dim</span>(im)[<span class="dv">3</span>]))

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files1)){
  allX[i,<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllRickImages/&quot;</span>, files1[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files2)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllMortyImages/&quot;</span>, files2[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files3)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/Both/&quot;</span>, files3[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files4)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)<span class="op">+</span><span class="kw">length</span>(files3),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/Neither/&quot;</span>, files4[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}</code></pre></div>
<p>As before we can costruct the output variable: a two dimensional output with <span class="math inline">\([1,0]\)</span> indicating Rick, <span class="math inline">\([0,1]\)</span> and Morty, <span class="math inline">\([1,1]\)</span> indicating both, and <span class="math inline">\([0,0]\)</span> neither.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">labels &lt;-<span class="st"> </span><span class="kw">rbind</span>(
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files1)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files2)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files3)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files4)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)
  )</code></pre></div>
<p>In total there are <span class="math inline">\(2213\)</span> Ricks, and <span class="math inline">\(2158\)</span> Mortys. We can split this data for training/validation as before:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>) <span class="co">#Set random number generator for R aspects of the session</span>

vecInd &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)<span class="op">+</span><span class="kw">length</span>(files3)<span class="op">+</span><span class="kw">length</span>(files4)) <span class="co">#A vector of indexes</span>
trainInd &lt;-<span class="st"> </span><span class="kw">sample</span>(vecInd)[<span class="dv">1</span><span class="op">:</span><span class="dv">4001</span>] <span class="co">#Permute and take first 4000 training</span>
<span class="co">#Train</span>
trainX &lt;-<span class="st"> </span>allX[trainInd, , , ]
trainY &lt;-<span class="st"> </span>labels[trainInd, ]
<span class="co">#Val</span>
valX &lt;-<span class="st"> </span>allX[<span class="op">-</span>trainInd, , , ]     
valY &lt;-<span class="st"> </span>labels[<span class="op">-</span>trainInd, ]</code></pre></div>
<p>And we can perform inference similarly to before, with the only real difference that we now have two output nodes with sigmoid activation: one asking is there a Rick, one asking is there a Morty.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_flatten</span>( ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/modelCNNMultClass_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_binary_accuracy&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;binary_accuracy&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size=</span><span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
</div>
<div id="categorical-cnn" class="section level2">
<h2><span class="header-section-number">4.4</span> Categorical CNN</h2>
<p>In the previous example we were using a binary classification since we were only concerned if an the image contained a Rick or not (or by extension if a Morty or not). A more general case is categorical classification (of which binary is a special case) where we have <span class="math inline">\(P\)</span> mutually exclusive classes, and wish to infer which one of those <span class="math inline">\(P\)</span>-classes is in a particular image. In this case we might want to infer Rick, Morty, or neither, so a three class system. Note that since we are framing this as exclusive question, we shoudn't really use any data with both Rick and Morty in.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">allX  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)<span class="op">+</span><span class="kw">length</span>(files4),<span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="kw">dim</span>(im)[<span class="dv">3</span>]))

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files1)){
  allX[i,<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllRickImages/&quot;</span>, files1[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files2)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllMortyImages/&quot;</span>, files2[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(files4)){
  allX[i<span class="op">+</span><span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2),<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="kw">dim</span>(im)[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/Neither/&quot;</span>, files4[i], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
}</code></pre></div>
<p>When using categorical data (Rick/Morty/Neither) we could instead represent this as a number or factor (1/2/3). This type of representation is still hard to use directly, and a much better represetation is via one-hot encoding, that is for each output we have vector of length <span class="math inline">\(P\)</span> with zeros everywhere exept the column represeting a particular class. So in our Rick, Morty, Neither system a Rick is <span class="math inline">\([1,0,0]\)</span>, and Morty is <span class="math inline">\([0,1,0]\)</span>, and Neither is <span class="math inline">\([0,0,1]\)</span>. Given a list of observations from a <span class="math inline">\(P\)</span>-class system we can one-hot encode using the {to_catogrical} function. In the snippet of code below we do this manually:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">labels &lt;-<span class="st"> </span><span class="kw">rbind</span>(
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files1)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files2)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(files4)))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>)
  )</code></pre></div>
<p>In this particular case we have a slight class imbalace with <span class="math inline">\(913\)</span> Ricks, <span class="math inline">\(858\)</span> Mortys, and <span class="math inline">\(2186\)</span> containing neither Rick nor Morty. As previously, we can construct a train/validation set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12345</span>) <span class="co">#Set random number generator for R aspects of the session</span>

vecInd &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="kw">length</span>(files1)<span class="op">+</span><span class="kw">length</span>(files2)<span class="op">+</span><span class="kw">length</span>(files4)) <span class="co">#A vector of indexes</span>
trainInd &lt;-<span class="st"> </span><span class="kw">sample</span>(vecInd)[<span class="dv">1</span><span class="op">:</span><span class="dv">3001</span>] <span class="co">#Permute and take first 4000 training</span>

<span class="co">#Train</span>
trainX &lt;-<span class="st"> </span>allX[trainInd, , , ]
trainY &lt;-<span class="st"> </span>labels[trainInd, ]

<span class="co">#Val</span>
valX &lt;-<span class="st"> </span>allX[<span class="op">-</span>trainInd, , , ]    
valY &lt;-<span class="st"> </span>labels[<span class="op">-</span>trainInd, ]</code></pre></div>
<p>And finally we run the code. Here we must make sure to use the appropriate activation funtion on the final layer and correct loss function/metrics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_flatten</span>( ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">3</span>, <span class="dt">activation =</span> <span class="st">&quot;softmax&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/modelCNNCat_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_categorical_accuracy&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;categorical_accuracy&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size=</span><span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>Note that if we were specifically interested, we could set out to address the class weights using the {class_weights} argument in the model fitting step. In this case class <span class="math inline">\(3\)</span> has almost <span class="math inline">\(3\)</span> times more<span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span>, so we want to upweight the underepresented classes by this amount:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainY, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valY), <span class="dt">class_weight =</span> <span class="kw">list</span>(<span class="st">&quot;0&quot;</span>=<span class="dv">3</span>,<span class="st">&quot;1&quot;</span>=<span class="dv">3</span>,<span class="st">&quot;2&quot;</span>=<span class="dv">1</span>), <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size=</span><span class="dv">100</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>I have already run this model for <span class="math inline">\(50\)</span> epochs (without adjusting for class imbalance) and saved as a .h5 model. Let's take a quick look at this model for prediction:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/modelCNNCat.h5&#39;</span>)

probvalY &lt;-<span class="st">  </span>model <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">predict</span>(valX)

<span class="co">#Find the instances where we the Rick probabilty is maximum and the image is a Rick:</span>
RickTP &lt;-<span class="st"> </span><span class="kw">which</span>( (probvalY[,<span class="dv">1</span>]<span class="op">&gt;</span>probvalY[,<span class="dv">2</span>]) <span class="op">&amp;</span><span class="st"> </span>(probvalY[,<span class="dv">1</span>]<span class="op">&gt;</span>probvalY[,<span class="dv">3</span>]) <span class="op">&amp;</span><span class="st"> </span>valY[,<span class="dv">1</span>]<span class="op">==</span><span class="dv">1</span> )
<span class="co">#Find the instances where we the Morty probabilty is maximum and the image is a Morty:</span>
MortyTP &lt;-<span class="st"> </span><span class="kw">which</span>( (probvalY[,<span class="dv">2</span>]<span class="op">&gt;</span>probvalY[,<span class="dv">1</span>]) <span class="op">&amp;</span><span class="st"> </span>(probvalY[,<span class="dv">2</span>]<span class="op">&gt;</span>probvalY[,<span class="dv">3</span>]) <span class="op">&amp;</span><span class="st"> </span>valY[,<span class="dv">2</span>]<span class="op">==</span><span class="dv">1</span> )</code></pre></div>
<p>Let's plot them, for Rick:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[RickTP[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[RickTP[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[RickTP[<span class="dv">3</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<p>And for Morty:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(valX[MortyTP[<span class="dv">1</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(valX[MortyTP[<span class="dv">2</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)
<span class="kw">grid.raster</span>(valX[MortyTP[<span class="dv">3</span>],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<div id="intepreting-cnn" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Intepreting CNN</h3>
<p>For these types of tasks, and besides the increaase performence, a key advantage of CNNs over densely connected networks lies in the increased interpretability. For example, for an optimised model and any given image we could take a look the feature representations at intermediate layers. In the snippet of code below, adapted from <a href="https://rstudio-conf-2020.github.io/dl-keras-tf/notebooks/visualizing-what-cnns-learn.nb.html">this tutorial</a> (which itself builds on <a href="https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html">this work</a>) we will take an example image and look at the activations in the first layer of the network: that is, we get a glimpse as to how the filters have processed a specific image.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/modelCNNCat.h5&#39;</span>)

tf<span class="op">$</span>compat<span class="op">$</span>v1<span class="op">$</span><span class="kw">disable_eager_execution</span>()

layer_outputs &lt;-<span class="st"> </span><span class="kw">lapply</span>(model<span class="op">$</span>layers[<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>], <span class="cf">function</span>(layer) layer<span class="op">$</span>output)
activation_model &lt;-<span class="st"> </span><span class="kw">keras_model</span>(<span class="dt">inputs =</span> model<span class="op">$</span>input, <span class="dt">outputs =</span> layer_outputs)

<span class="co">#Choice here is just an index for a given image. So here we just look at the 1st TP Rick image in the validation set</span>
choice =<span class="st"> </span><span class="dv">1</span>
activations &lt;-<span class="st"> </span>activation_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>( <span class="kw">array_reshape</span>( valX[RickTP[choice],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] , <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">90</span>, <span class="dv">160</span>, <span class="dv">3</span>) ) )
first_layer_activation &lt;-<span class="st"> </span>activations[[<span class="dv">1</span>]]</code></pre></div>
<p>Recall that the first layer is an array of size <span class="math inline">\(86 \times 156 \times 20\)</span>. That is, 20 different feature representations of <span class="math inline">\(86 \times 146\)</span> (we can check the expected size of individual layers by looking at the model summary). Our output here should be the same as this. We will visualise some of these <span class="math inline">\(20\)</span> feature representations (alongside the image itself). First the image:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>( valX[RickTP[choice],<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] , <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)</code></pre></div>
<p>And now the feature maps <span class="math inline">\(1,2,3,4,5,10,12,15\)</span> and <span class="math inline">\(20\)</span> (note the code is a little extra below, since the feature representations need to be rotated).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>))
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">1</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">1</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">2</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">2</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">3</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">3</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">4</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">4</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">5</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">5</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">10</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">10</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">12</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">12</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">15</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">15</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">image</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">20</span>])[,<span class="kw">ncol</span>(<span class="kw">t</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">20</span>]))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span> )
<span class="kw">par</span>(op)</code></pre></div>
<p>We can see from these representations a general similarity to the original plot, but certain parts have been emphasized. We could similarly take a look at the feature representations deeper in the network:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">image_width &lt;-<span class="st"> </span><span class="dv">56</span>
images_per_row &lt;-<span class="st"> </span><span class="dv">5</span>

i &lt;-<span class="st"> </span><span class="dv">7</span>
  
layer_activation &lt;-<span class="st"> </span>activations[[i]]
layer_name &lt;-<span class="st"> </span>model<span class="op">$</span>layers[[i]]<span class="op">$</span>name
 
n_features &lt;-<span class="st"> </span><span class="kw">dim</span>(layer_activation)[[<span class="dv">4</span>]]
n_cols &lt;-<span class="st"> </span>n_features <span class="op">%/%</span><span class="st"> </span>images_per_row
 
op &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(n_cols, images_per_row), <span class="dt">mai =</span> <span class="kw">rep_len</span>(<span class="fl">0.02</span>, <span class="dv">4</span>))
  
<span class="cf">for</span> (col <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(n_cols <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {
  <span class="cf">for</span> (row <span class="cf">in</span> <span class="dv">0</span><span class="op">:</span>(images_per_row <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {
      channel_image &lt;-<span class="st"> </span>layer_activation[<span class="dv">1</span>,,,(col<span class="op">*</span>images_per_row) <span class="op">+</span><span class="st"> </span>row <span class="op">+</span><span class="st"> </span><span class="dv">1</span>]
      <span class="kw">image</span>(<span class="kw">t</span>(channel_image)[,<span class="kw">ncol</span>(<span class="kw">t</span>(channel_image))<span class="op">:</span><span class="dv">1</span>], <span class="dt">axes =</span> <span class="ot">FALSE</span>,)
  }
}
  
<span class="kw">par</span>(op)</code></pre></div>
<p>At higher layers, the features have become far less recognisable and now, and represent specific features that can be built up to perform classification.</p>
</div>
<div id="class-activation" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Class activation</h3>
<p>Further to visualising the feature represetations, we can also begin to visualise how particular regions activate to a particular class i.e., identify what pixels the CNN is concentrating on when looking classifying an image as Rick.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">choice &lt;-<span class="st"> </span><span class="dv">7</span>

X0 &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllRickImages/&quot;</span>, files1[choice], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
imag_pred &lt;-<span class="st"> </span><span class="kw">array_reshape</span>(X0[<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] , <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">90</span>, <span class="dv">160</span>, <span class="dv">3</span>) )

<span class="kw">predict</span>(model, imag_pred)

<span class="co"># Prediction vector, in this case class 1 is Rick</span>
d_output &lt;-<span class="st"> </span>model<span class="op">$</span>output[, <span class="dv">1</span>]

<span class="co">#The last convolutional layer (you will need to know what this layer is called for your network, which can be done by looking at the model summary. In this case, because you&#39;re using my precalculated network there is no need to change things)</span>
last_conv_layer &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">get_layer</span>(<span class="st">&quot;conv2d_20&quot;</span>)

<span class="co"># This is the gradient of the &quot;Rick&quot; class with respect to the output feature map of `conv2d_20`</span>
grads &lt;-<span class="st"> </span><span class="kw">k_gradients</span>(d_output, last_conv_layer<span class="op">$</span>output)[[<span class="dv">1</span>]]
pooled_grads &lt;-<span class="st"> </span><span class="kw">k_mean</span>(grads, <span class="dt">axis =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))

<span class="co">#Function to access the values of `pooled_grads` and output feature map of `conv2d_20`, given a sample image</span>
iterate &lt;-<span class="st"> </span><span class="kw">k_function</span>(<span class="kw">list</span>(model<span class="op">$</span>input),<span class="kw">list</span>(pooled_grads, last_conv_layer<span class="op">$</span>output[<span class="dv">1</span>,,,]))
<span class="kw">c</span>(pooled_grads_value, conv_layer_output_value) <span class="op">%&lt;-%</span><span class="st"> </span><span class="kw">iterate</span>(<span class="kw">list</span>( imag_pred  ))

<span class="co">#Multiply each channel in the feature map array by &quot;how important this channel is&quot; with regard to the Rick class</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">64</span>) {
  conv_layer_output_value[,,i] &lt;-<span class="st"> </span>conv_layer_output_value[,,i] <span class="op">*</span><span class="st"> </span>pooled_grads_value[[i]] 
}

<span class="co">#Channel-wise mean of the resulting feature map is our heatmap of class activation</span>
heatmap &lt;-<span class="st"> </span><span class="kw">apply</span>(conv_layer_output_value, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), mean)

<span class="co">#A whole lot of plotting:</span>

heatmap &lt;-<span class="st"> </span><span class="kw">pmax</span>(heatmap, <span class="dv">0</span>) 
heatmap &lt;-<span class="st"> </span>heatmap <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(heatmap)
write_heatmap &lt;-<span class="st"> </span><span class="cf">function</span>(heatmap, filename, <span class="dt">width =</span> <span class="dv">150</span>, <span class="dt">height =</span> <span class="dv">150</span>,<span class="dt">bg =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">col =</span> <span class="kw">terrain.colors</span>(<span class="dv">12</span>)) {
  <span class="kw">png</span>(filename, <span class="dt">width =</span> width, <span class="dt">height =</span> height, <span class="dt">bg =</span> bg)
  op =<span class="st"> </span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>))
  <span class="kw">on.exit</span>({<span class="kw">par</span>(op); <span class="kw">dev.off</span>()}, <span class="dt">add =</span> <span class="ot">TRUE</span>)
  rotate &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">t</span>(<span class="kw">apply</span>(x, <span class="dv">2</span>, rev))
  <span class="kw">image</span>(<span class="kw">rotate</span>(heatmap), <span class="dt">axes =</span> <span class="ot">FALSE</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> col)
}
<span class="kw">write_heatmap</span>(heatmap, <span class="st">&quot;data/RickandMorty/RM_heatmap.png&quot;</span>) 

<span class="kw">library</span>(magick) 
<span class="kw">library</span>(viridis) 

image &lt;-<span class="st"> </span><span class="kw">image_read</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllRickImages/&quot;</span>, files1[choice], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
info &lt;-<span class="st"> </span><span class="kw">image_info</span>(image) 
geometry &lt;-<span class="st"> </span><span class="kw">sprintf</span>(<span class="st">&quot;%dx%d!&quot;</span>, info<span class="op">$</span>width, info<span class="op">$</span>height) 
pal &lt;-<span class="st"> </span><span class="kw">col2rgb</span>(<span class="kw">viridis</span>(<span class="dv">20</span>), <span class="dt">alpha =</span> <span class="ot">TRUE</span>) 
alpha &lt;-<span class="st"> </span><span class="kw">floor</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dt">length =</span> <span class="kw">ncol</span>(pal))) 
pal_col &lt;-<span class="st"> </span><span class="kw">rgb</span>(<span class="kw">t</span>(pal), <span class="dt">alpha =</span> alpha, <span class="dt">maxColorValue =</span> <span class="dv">255</span>)
<span class="kw">write_heatmap</span>(heatmap, <span class="st">&quot;data/RickandMorty/RM_overlay.png&quot;</span>, <span class="dt">width =</span> <span class="dv">14</span>, <span class="dt">height =</span> <span class="dv">14</span>, <span class="dt">bg =</span> <span class="ot">NA</span>, <span class="dt">col =</span> pal_col) 
<span class="co"># Overlay the heatmap</span>
<span class="kw">image_read</span>(<span class="st">&quot;data/RickandMorty/RM_overlay.png&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">image_resize</span>(geometry, <span class="dt">filter =</span> <span class="st">&quot;quadratic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">image_composite</span>(image, <span class="dt">operator =</span> <span class="st">&quot;blend&quot;</span>, <span class="dt">compose_args =</span> <span class="st">&quot;20&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>() </code></pre></div>
<p>We can have a look at where the CNN focuses on a set of Morty images.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">choice &lt;-<span class="st"> </span><span class="dv">30</span>

X0 &lt;-<span class="st"> </span><span class="kw">readJPEG</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllMortyImages/&quot;</span>, files2[choice], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))
imag_pred &lt;-<span class="st"> </span><span class="kw">array_reshape</span>(X0[<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] , <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">90</span>, <span class="dv">160</span>, <span class="dv">3</span>) )

<span class="kw">predict</span>(model, imag_pred)
d_output &lt;-<span class="st"> </span>model<span class="op">$</span>output[, <span class="dv">2</span>]
last_conv_layer &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">get_layer</span>(<span class="st">&quot;conv2d_20&quot;</span>)
grads &lt;-<span class="st"> </span><span class="kw">k_gradients</span>(d_output, last_conv_layer<span class="op">$</span>output)[[<span class="dv">1</span>]]
pooled_grads &lt;-<span class="st"> </span><span class="kw">k_mean</span>(grads, <span class="dt">axis =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))
iterate &lt;-<span class="st"> </span><span class="kw">k_function</span>(<span class="kw">list</span>(model<span class="op">$</span>input),<span class="kw">list</span>(pooled_grads, last_conv_layer<span class="op">$</span>output[<span class="dv">1</span>,,,]))
<span class="kw">c</span>(pooled_grads_value, conv_layer_output_value) <span class="op">%&lt;-%</span><span class="st"> </span><span class="kw">iterate</span>(<span class="kw">list</span>( imag_pred  ))

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">64</span>) {
  conv_layer_output_value[,,i] &lt;-<span class="st"> </span>conv_layer_output_value[,,i] <span class="op">*</span><span class="st"> </span>pooled_grads_value[[i]] 
}

heatmap &lt;-<span class="st"> </span><span class="kw">apply</span>(conv_layer_output_value, <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), mean)
heatmap &lt;-<span class="st"> </span><span class="kw">pmax</span>(heatmap, <span class="dv">0</span>) 
heatmap &lt;-<span class="st"> </span>heatmap <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(heatmap)
write_heatmap &lt;-<span class="st"> </span><span class="cf">function</span>(heatmap, filename, <span class="dt">width =</span> <span class="dv">150</span>, <span class="dt">height =</span> <span class="dv">150</span>, <span class="dt">bg =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">col =</span> <span class="kw">terrain.colors</span>(<span class="dv">12</span>)) {
  <span class="kw">png</span>(filename, <span class="dt">width =</span> width, <span class="dt">height =</span> height, <span class="dt">bg =</span> bg)
  op =<span class="st"> </span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>))
  <span class="kw">on.exit</span>({<span class="kw">par</span>(op); <span class="kw">dev.off</span>()}, <span class="dt">add =</span> <span class="ot">TRUE</span>)
  rotate &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">t</span>(<span class="kw">apply</span>(x, <span class="dv">2</span>, rev))
  <span class="kw">image</span>(<span class="kw">rotate</span>(heatmap), <span class="dt">axes =</span> <span class="ot">FALSE</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> col)
}
<span class="kw">write_heatmap</span>(heatmap, <span class="st">&quot;data/RickandMorty/RM_heatmap.png&quot;</span>) 

<span class="kw">library</span>(magick) 
<span class="kw">library</span>(viridis) 

image &lt;-<span class="st"> </span><span class="kw">image_read</span>(<span class="kw">paste</span>(<span class="st">&quot;data/RickandMorty/data/ThreeClassModel/AllMortyImages/&quot;</span>, files2[choice], <span class="dt">sep=</span><span class="st">&quot;&quot;</span>))

info &lt;-<span class="st"> </span><span class="kw">image_info</span>(image) 
geometry &lt;-<span class="st"> </span><span class="kw">sprintf</span>(<span class="st">&quot;%dx%d!&quot;</span>, info<span class="op">$</span>width, info<span class="op">$</span>height) 
pal &lt;-<span class="st"> </span><span class="kw">col2rgb</span>(<span class="kw">viridis</span>(<span class="dv">20</span>), <span class="dt">alpha =</span> <span class="ot">TRUE</span>) 
alpha &lt;-<span class="st"> </span><span class="kw">floor</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dt">length =</span> <span class="kw">ncol</span>(pal))) 
pal_col &lt;-<span class="st"> </span><span class="kw">rgb</span>(<span class="kw">t</span>(pal), <span class="dt">alpha =</span> alpha, <span class="dt">maxColorValue =</span> <span class="dv">255</span>)
<span class="kw">write_heatmap</span>(heatmap, <span class="st">&quot;data/RickandMorty/RM_overlay.png&quot;</span>, <span class="dt">width =</span> <span class="dv">14</span>, <span class="dt">height =</span> <span class="dv">14</span>, <span class="dt">bg =</span> <span class="ot">NA</span>, <span class="dt">col =</span> pal_col) 
<span class="kw">image_read</span>(<span class="st">&quot;data/RickandMorty/RM_overlay.png&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">image_resize</span>(geometry, <span class="dt">filter =</span> <span class="st">&quot;quadratic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">image_composite</span>(image, <span class="dt">operator =</span> <span class="st">&quot;blend&quot;</span>, <span class="dt">compose_args =</span> <span class="st">&quot;20&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>() </code></pre></div>
</div>
</div>
<div id="cnns-for-motif-analysis" class="section level2">
<h2><span class="header-section-number">4.5</span> CNNs for Motif analysis</h2>
<p>Aside from image analyses, CNNs have also bee useful for studying other types of data including genomic data such as DNA-sequence analysis, and DNA-methylation or histone modificaiton data. The use of CNNs for studying regulatory motifs in genomic sequecing data as been reviewed in <a href="https://academic.oup.com/bib/article/23/1/bbab374/6381249"><span class="citation">(Zhang et al. <a href="#ref-zhang2022assessing">2022</a>)</span></a>. Alhough no longer considered state-of-the art, CNNs for these applications still find practical use, particularly when combined with more recent developments such as recurrent neural networks.</p>
<p>In the example below we code for a simple CNN which aims to identify if a particular <span class="math inline">\(200\)</span>bp genomic region contains a SOX17 or PRDM1 binding site. The data is based on ChIP-sequencig data taken from <a href="https://pubmed.ncbi.nlm.nih.gov/35411086/"><span class="citation">(Tang et al. <a href="#ref-tang2022sequential">2022</a>)</span></a> and is avaible to download at NCBI GEO (GSE159654). Briefly, this dataset consists of ChIP-sequencing indicating the binding of two trascription factors, SOX17 and PRDM1, that play a role in the specification of the germline. Here the work makes use of an in vitro model based on pluripotent stem cells to derived embryonnic precursors of sperm and eggs, the primordial germ cells. For this section, peaks from individual replicates were concatenated and overlapping regions merged using bedtools, and a final list of regions for each TF was generated based on the centre of these peaks plus or minus <span class="math inline">\(100\)</span>bp. Regions with both a SOX17 and PRDM1 binding site were excluded. For further comparison a random set of genomic sequences were sampled from the human genome. Finallly, geomic sequencecs associated with human genome hg38 extracted using bedtools getfasta. The processing steps can be found in the file data/ChIP/processdata.sh.</p>
<p>In the sippet of code below we use the Biostrings package to read in the fasta files for SOX17, PRDM1, and random regions. Dealing directly with a sequence string is difficult, so to make inferece easier we first one-hot the sequence s i.e., instead of representing a particular base pair as A, C, G, or T, these will instead be represened as <span class="math inline">\(A \to [1,0,0,0]\)</span>, <span class="math inline">\(C \to [0,1,0,0]\)</span>, <span class="math inline">\(G \to [0,0,1,0]\)</span>, <span class="math inline">\(T \to [0,0,0,1]\)</span>. Each basepair will be treated as a seperate &quot;colour channel&quot;, and the iput data is a <span class="math inline">\(200 \timmes 4\)</span> array. In total we have <span class="math inline">\(13,065\)</span> sequences for SOX17, <span class="math inline">\(22,255\)</span> for PRDM1, and <span class="math inline">\(21,921\)</span> random regions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Biostrings)</code></pre></div>
<pre><code>## Warning: package &#39;Biostrings&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Loading required package: BiocGenerics</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## 
## Attaching package: &#39;BiocGenerics&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:parallel&#39;:
## 
##     clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
##     clusterExport, clusterMap, parApply, parCapply, parLapply,
##     parLapplyLB, parRapply, parSapply, parSapplyLB</code></pre>
<pre><code>## The following object is masked from &#39;package:keras&#39;:
## 
##     normalize</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     combine, intersect, setdiff, union</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     IQR, mad, sd, var, xtabs</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     anyDuplicated, append, as.data.frame, basename, cbind, colMeans,
##     colnames, colSums, dirname, do.call, duplicated, eval, evalq,
##     Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply,
##     lengths, Map, mapply, match, mget, order, paste, pmax, pmax.int,
##     pmin, pmin.int, Position, rank, rbind, Reduce, rowMeans, rownames,
##     rowSums, sapply, setdiff, sort, table, tapply, union, unique,
##     unsplit, which, which.max, which.min</code></pre>
<pre><code>## Loading required package: S4Vectors</code></pre>
<pre><code>## Loading required package: stats4</code></pre>
<pre><code>## 
## Attaching package: &#39;S4Vectors&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     first, rename</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     expand.grid</code></pre>
<pre><code>## Loading required package: IRanges</code></pre>
<pre><code>## 
## Attaching package: &#39;IRanges&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     collapse, desc, slice</code></pre>
<pre><code>## Loading required package: XVector</code></pre>
<pre><code>## 
## Attaching package: &#39;Biostrings&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     strsplit</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(abind)

SOX17 &lt;-<span class="st"> </span><span class="kw">readDNAStringSet</span>(<span class="st">&quot;data/ChIP/SOX17.fa&quot;</span>)
SOXseq &lt;-<span class="st"> </span><span class="kw">paste</span>(SOX17)
allS17  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(SOXseq),<span class="dv">200</span>,<span class="dv">4</span>))
 
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(SOXseq)){
         allS17[i,<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>] &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">4</span>)[<span class="kw">match</span>(<span class="kw">unlist</span>(<span class="kw">lapply</span>(SOXseq[i], utf8ToInt)), <span class="kw">utf8ToInt</span>(<span class="st">&quot;ACGT&quot;</span>)), ]
}

PRDM1 &lt;-<span class="st"> </span><span class="kw">readDNAStringSet</span>(<span class="st">&quot;data/ChIP/PRDM1.fa&quot;</span>)
PRDMseq &lt;-<span class="st"> </span><span class="kw">paste</span>(PRDM1)
allP1  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(PRDMseq),<span class="dv">200</span>,<span class="dv">4</span>))

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(PRDMseq)){
         allP1[i,<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>] &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">4</span>)[<span class="kw">match</span>(<span class="kw">unlist</span>(<span class="kw">lapply</span>(PRDMseq[i], utf8ToInt)), <span class="kw">utf8ToInt</span>(<span class="st">&quot;ACGT&quot;</span>)), ]
         }

RANDOM1 &lt;-<span class="st"> </span><span class="kw">readDNAStringSet</span>(<span class="st">&quot;data/ChIP/random.fa&quot;</span>)
Rseq &lt;-<span class="st"> </span><span class="kw">paste</span>(RANDOM1)
allR1  &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dv">0</span>, <span class="dt">dim=</span><span class="kw">c</span>(<span class="kw">length</span>(Rseq),<span class="dv">200</span>,<span class="dv">4</span>))
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(Rseq)){
         allR1[i,<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>] &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="dv">4</span>)[<span class="kw">match</span>(<span class="kw">unlist</span>(<span class="kw">lapply</span>(Rseq[i], utf8ToInt)), <span class="kw">utf8ToInt</span>(<span class="st">&quot;ACGT&quot;</span>)), ]
}

<span class="co">#We need to filter out NNNN sequeces</span>
allR1 &lt;-<span class="st"> </span>allR1[<span class="kw">is.na</span>(<span class="kw">rowSums</span>(<span class="kw">rowSums</span>(allR1, <span class="dt">dims =</span> <span class="dv">2</span>), <span class="dt">dims =</span> <span class="dv">1</span> ))<span class="op">==</span><span class="ot">FALSE</span>, , ]
allTFX &lt;-<span class="st"> </span><span class="kw">abind</span>(allS17, allP1, allR1, <span class="dt">along =</span> <span class="dv">1</span>)</code></pre></div>
<p>Based on the way we have processed the data, our ChIP dataset represets a <span class="math inline">\(3\)</span> class system: any given sequence may contain either a SOX17-binding region, a PRDM1-binding region, or a randomly sampled sequece without SOX17/PRDM1-binding. For this example we could therefore treat this as categorical classification, with the peaks one-hot encoded, such that a SOX17 peak is represented as <span class="math inline">\([1,0,0]\)</span>, a PRDM1 peak as <span class="math inline">\([0,1,0]\)</span>, and the random sequences as <span class="math inline">\([0,0,1]\)</span>. Below we generate a random training and test set for the model by radomly splitting the dataset (<span class="math inline">\(40,000\)</span> for training and <span class="math inline">\(17,241\)</span> for validation). In general, this may not be the optimal way to split the data, particularly if we are interested in esuring the inferences are generalisable. Other ways to split would be to train on data from a subset of chromosomes (or on one replicate) and test on the remainder (or independent biological replicate); alteratively, in some casaes, it may be of interest to train on data from one cell type or condition type and predict on another, or even train on one species and predict an another. There are caveats, of course, and such splitting won't always be appropriate; ultimately, the decision will be influenced by our biological questions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">labels &lt;-<span class="st"> </span><span class="kw">rbind</span>(
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">dim</span>(allS17)[<span class="dv">1</span>] ))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">dim</span>(allP1)[<span class="dv">1</span>] ))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),
  <span class="kw">t</span>(<span class="kw">t</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">dim</span>(allR1)[<span class="dv">1</span>] ))) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>)  
  )

vecInd &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">dim</span>(allTFX)[<span class="dv">1</span>] ) <span class="co">#A vector of indexes</span>
trainInd &lt;-<span class="st"> </span><span class="kw">sample</span>(vecInd)[<span class="dv">1</span><span class="op">:</span><span class="dv">40000</span>] <span class="co">#Permute and take first 4000 training</span>


allTFX_train &lt;-<span class="st"> </span>allTFX[trainInd, , ]
allTFX_test &lt;-<span class="st"> </span>allTFX[<span class="op">-</span>trainInd, ,]

allYtrain &lt;-<span class="st"> </span>labels[trainInd,]
allYtest &lt;-<span class="st"> </span>labels[<span class="op">-</span>trainInd,]</code></pre></div>
<p>Finally, we are ready to encode a model and perform inference. Here we have a three class classification system with a sequence associated with either SOX17, PRDM1, or a random region, so can use a categorical approach (thus use a softmax activation on the final level and use categorical cross etrophy and accuracy). Technically, we only have mutually exclusive categories because we have filtered the regios to esure there are no overlapping ones; within the genome we may - and in our case do - get cases where SOX17/PRDM1 co-bind, so if we were interested in this aspect of biology, we might istead treat our data as a two-node binary classification for SOX17 and PRDM1. Below we code a simple CNN consisting of two 1D convolution layers (each with a 1D pooling layer).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_1d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">200</span>,<span class="dv">4</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_1d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_1d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_max_pooling_1d</span>(<span class="dt">pool_size=</span><span class="kw">c</span>(<span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_flatten</span>( ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units=</span><span class="dv">3</span>, <span class="dt">activation =</span> <span class="st">&quot;softmax&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/modelCNNTF_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_categorical_accuracy&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;sgd&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;categorical_accuracy&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> allTFX_train, <span class="dt">y =</span> allYtrain , <span class="dt">validation_data =</span> <span class="kw">list</span>(allTFX_test, allYtest), <span class="dt">epochs =</span> <span class="dv">5</span>, <span class="dt">batch_size=</span><span class="dv">1000</span>, <span class="dt">verbose =</span> <span class="dv">0</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>If we run this snippet of code we see the beginings of a increase in accuracy; this accuracy begins to plateau after around <span class="math inline">\(300\)</span> epochs (I have saved this model as 'data/RickandMorty/data/models/modelCNNTF.h5') where it hits around <span class="math inline">\(70\%\)</span> accuracy. We have thus trained an algorithm to predict if a particcualr genomic sequence is a potential target of a particular TF. We could, of course, aim to increase this accuracy by tweaking the arcitecture, and the here we might want to follow the mantra &quot;don't be a hero&quot;. That is, try arcitectures that have been shown to work well on these sorts of tasks. I will leave this to the individuals to play around with. For ispiration see the various approaches in <a href="https://academic.oup.com/bib/article/23/1/bbab374/6381249"><span class="citation">(Zhang et al. <a href="#ref-zhang2022assessing">2022</a>)</span></a>.</p>
<p>Excercise 2.2: Try visualising what the algorithm is looking at within a sequence region (hint: this is slightly different to image analysis. Start with a given motif and calculating how much the probability of mapping to the correct label changes when you perturb one base pair e.g., set that basepair to <span class="math inline">\([0,0,0,0]\)</span>, then roll this out systematically for each base pair in turn). A useuful source for inspiration can be found <a href="https://github.com/const-ae/Neural_Network_DNA_Demo/blob/master/nn_for_sequence_data.ipynb">here</a></p>
</div>
<div id="data-augmentation" class="section level2">
<h2><span class="header-section-number">4.6</span> Data augmentation</h2>
<p>Although we saw some improvements when using convolutional neural networks compared to densely connected one, the end results were not particularly convincing. After all, previous applications in the recognition of handwritten digits (0-9) showed above human accuracy, see e.g., <a href="http://neuralnetworksanddeeplearning.com/chap3.html">Neural Networks and Deep Learning</a>. Our accuracy for image analysis pushed approximately <span class="math inline">\(90\)</span> percent, whilst our TF example was closer to <span class="math inline">\(70\)</span> percent, neither of which close to human levels. So where are we gong wrong?</p>
<p>We should, of course, start by considering the number of parameters versus the size of the training dataset. In our final model we had many parameters, and only a few thousand training images, so it is perhaps not surprising that our model is doing relatively poorly. In previous examples of digit recognition more than <span class="math inline">\(10,000\)</span> images were used, whilst better known examples of <em>deep learning</em> for image classification make use of millions of images. Our task is also, arguably, a lot harder than digit recognition. After all, a handwritten <span class="math inline">\(0\)</span> is relatively similar regardless of who wrote it. Rick Sanchez, on the other hand, can come in a diverse range of guises, with different postures, facial expressions, clothing, and even in pickle-Rick form. We may well need a vastly increased number of training images: with more training data, we can begin to learn more robustly what features define a <em>Rick</em>. Whilst we could simply download more data from <a href="https://masterofallscience.com">Master of All Science</a>, an alternative approach is to artificially increase our pool of training data by manipulating the images. For example, we could shear, warp or rotate some of the images in our training set; we could add noise and we could manipulate the colouring. This can be done using the data generators ({image_data_generator}) alongside ({flow_images_from_directory}), which will essentially load data in from a folder, modify it in some customisable sort of way, and pass over to the network for training, essentially allowing infinite data from a limited one. Whilst this is certainly useful, and often increases accuracy, one should be careful that the new &quot;infinite&quot; data source is really representative and that you don't end up simply learning the specifics of a subset of your training/validation set. Careful consideration also needs to be give as to what alterationns to the dataset means: for example, shearing or slightly colour changes to a Rick still leaves a Rick, however random perturbations to DNA-sequence data could, in reality, change the class, particularly if you hit the exat binding region. An alternative for sequence data would be a shift, i.e, move the sequence a random distance up or downstream (so long as you think the core of whatever you aim to capture -- usually a small motif -- remains with the sequence itself).</p>
<p>Excercise 2.3: Try coding a CNN for image analysis using laading data direct from their folders, rather than loading each to memory. Hint: look up the functions {image_data_generator} and {flow_images_from_directory}.</p>
<div id="transfer-learning" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Transfer learning</h3>
<p>Another approach that might help us increase our accuracy is to use <strong>transfer learning</strong>. This is where we make use of existing neural networks to make predictions about our specific datasets, usually by fixing the topology and parameters of the uppermost layers and fine tuning the lower layers to our dataset. For image recognition we could make use of top perfoming neural networks on the <a href="http://www.image-net.org">ImageNet</a> database, although these types of large-scale models are certainly not without their issues <span class="citation">(Prabhu and Birhane <a href="#ref-Prabhu2020">2020</a>)</span>. Whilst none of these networks would have been designed to identify <em>Rick</em> they would have been trained on millions of images, and the top level representations would have been able to extract useful general features that allowed identification of images which might hold for our images too.</p>
</div>
<div id="more-complex-networks" class="section level3">
<h3><span class="header-section-number">4.6.2</span> More complex networks</h3>
<p>More complex learning algorithms can easily be built using Keras via the model class API. This allows, for example, learning from multiple inputs and/or predicting multiple outputs, with more interconnection between the different layers. We might, for example, want to include additional contextual information about the image that could serve to augment the predictions. For our sequence data we might want to allow several different filters of different sizes to run across the sequence, effectively allowing motifs of different sizes to be present in the dataset.</p>
</div>
</div>
<div id="autoencoders" class="section level2">
<h2><span class="header-section-number">4.7</span> Autoencoders</h2>
<p>In previous sections we have used CNNs to build a <em>Rick</em>/<em>not Rick</em> classifier. In doing so we are halfway towards other interesting neural network architectures, including <a href="https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368">autoencoders</a>.</p>
<p>One type of autoencoder consists of a stack of convolution/max pooling layers which served to condense the original image down into a reduced dimensional (encoded) representation, with a stack of <em>upsampled</em> layers used to decode the encoded layer (Figure <a href="mlnn.html#fig:AE">4.2</a>). Within such a network the input and output data are an identical image: we are therefore training a network that can both compresses the original high resolution data and subsequently interpret that compressed representation to recreate the original as closely as possible. A slight deviation of this principle would be to use noisy versions of the image as input, with clean versions as the output. In these cases the autoencoder becomes a denoiser (Figure <a href="mlnn.html#fig:AE2">4.3</a>). Similar methods can be used for generating higher resolution versions of an image (or from noise).</p>
<div class="figure" style="text-align: center"><span id="fig:AE"></span>
<img src="images/AE.png" alt="Example of an autoencoder" width="50%" />
<p class="caption">
Figure 4.2: Example of an autoencoder
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:AE2"></span>
<img src="images/AE2.png" alt="Example of an autoencoder " width="50%" />
<p class="caption">
Figure 4.3: Example of an autoencoder
</p>
</div>
<p>In the example below we implement a simple Autoencoder, constructed by stacking a number of convolution layers with a stak of deconvolution layers (foregoing the max pooling layers). Note that in, in R, each pixel is represented as a number between 1 and 0. A suitable final activation function is therefore one that scales between 0 and 1 e.g., a sigmoid function. Nevertheless, we are not doing logistic regrssion, so we will choose to monitor the mse. Note that this snippet of code will take a good few hours to run <span class="math inline">\(50\)</span> epochs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">input_shape =</span> <span class="kw">list</span>(<span class="dv">90</span>,<span class="dv">160</span>,<span class="dv">3</span>), <span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d_transpose</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d_transpose</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d_transpose</span>(<span class="dt">filters =</span> <span class="dv">20</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">3</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>), <span class="dt">padding =</span> <span class="st">&#39;same&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_activation</span>(<span class="st">&quot;sigmoid&quot;</span>)

cp_callback &lt;-<span class="st"> </span><span class="kw">callback_model_checkpoint</span>(<span class="dt">filepath =</span> <span class="st">&#39;data/RickandMorty/data/models/modelAE_rerun.h5&#39;</span>,<span class="dt">save_weights_only =</span> <span class="ot">FALSE</span>, <span class="dt">mode =</span> <span class="st">&quot;auto&quot;</span>,  <span class="dt">monitor =</span> <span class="st">&quot;val_mse&quot;</span>, <span class="dt">verbose =</span> <span class="dv">0</span>)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>, <span class="dt">optimizer =</span> <span class="st">&quot;adam&quot;</span>, <span class="dt">metrics =</span> <span class="st">&quot;mse&quot;</span>)

tensorflow<span class="op">::</span><span class="kw">set_random_seed</span>(<span class="dv">42</span>)
model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(<span class="dt">x =</span> trainX, <span class="dt">y =</span> trainX, <span class="dt">validation_data =</span> <span class="kw">list</span>(valX, valX), <span class="dt">epochs =</span> <span class="dv">25</span>, <span class="dt">verbose =</span> <span class="dv">2</span>, <span class="dt">callbacks =</span> <span class="kw">list</span>(cp_callback))</code></pre></div>
<p>Instead of running this snippet again, we can load in a pre-run model I already saved.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&#39;data/RickandMorty/data/models/modelAE.h5&#39;</span>)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## Model: &quot;sequential_7&quot;
## ________________________________________________________________________________
##  Layer (type)                       Output Shape                    Param #     
## ================================================================================
##  conv2d_3 (Conv2D)                  (None, 86, 156, 20)             1520        
##                                                                                 
##  activation_3 (Activation)          (None, 86, 156, 20)             0           
##                                                                                 
##  conv2d_4 (Conv2D)                  (None, 82, 152, 20)             10020       
##                                                                                 
##  activation_4 (Activation)          (None, 82, 152, 20)             0           
##                                                                                 
##  conv2d_5 (Conv2D)                  (None, 78, 148, 64)             32064       
##                                                                                 
##  activation_5 (Activation)          (None, 78, 148, 64)             0           
##                                                                                 
##  conv2d_transpose (Conv2DTranspose)  (None, 82, 152, 64)            102464      
##                                                                                 
##  activation_6 (Activation)          (None, 82, 152, 64)             0           
##                                                                                 
##  conv2d_transpose_1 (Conv2DTranspos  (None, 86, 156, 20)            32020       
##  e)                                                                             
##                                                                                 
##  activation_7 (Activation)          (None, 86, 156, 20)             0           
##                                                                                 
##  conv2d_transpose_2 (Conv2DTranspos  (None, 90, 160, 20)            10020       
##  e)                                                                             
##                                                                                 
##  activation_8 (Activation)          (None, 90, 160, 20)             0           
##                                                                                 
##  conv2d_6 (Conv2D)                  (None, 90, 160, 3)              1503        
##                                                                                 
##  activation_9 (Activation)          (None, 90, 160, 3)              0           
##                                                                                 
## ================================================================================
## Total params: 189,611
## Trainable params: 189,611
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<p>We can see that this model condenses down the images from <span class="math inline">\(90 \times 160\)</span> pixel images down to <span class="math inline">\(78 \times 148\)</span> (not a huge compression, but a good starting point to illustrate thigs). Let's try compressing (and decompressing) a few of the held out examples:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictAEX &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(predictX)

grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(predictX[<span class="dv">1</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(predictAEX[<span class="dv">1</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(predictX[<span class="dv">2</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(predictAEX[<span class="dv">2</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">grid<span class="op">::</span><span class="kw">grid.newpage</span>()
<span class="kw">grid.raster</span>(predictX[<span class="dv">3</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.2</span>)
<span class="kw">grid.raster</span>(predictAEX[<span class="dv">3</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">90</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">160</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="dt">interpolate=</span><span class="ot">FALSE</span>, <span class="dt">width =</span> <span class="fl">0.3</span>, <span class="dt">x =</span> <span class="fl">0.5</span>, <span class="dt">y=</span><span class="fl">0.5</span>)</code></pre></div>
<p><img src="12-deep-learning_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<p>Exercise 2.4: Think about how the script can be modified to demonstrate the use of a denoisiny algorithm (hint: the dataset will need to be modified in some way, but the algorithm itself should be functional as is).</p>
</div>
<div id="further-reading" class="section level2">
<h2><span class="header-section-number">4.8</span> Further reading</h2>
<p>A particularly comprehensive introduction to <em>Deep Learning</em> can be found in <a href="http://neuralnetworksanddeeplearning.com/chap3.html">Neural Networks and Deep Learning</a>, written by Michael Nielsen.</p>
<p>Useful examples can also be found in the <a href="https://keras.io">keras documentation</a>, with many more examples found in the keras <a href="https://keras.rstudio.com/index.html">R wrapper documentation</a>.</p>
<p><a href="https://www.manning.com/books/deep-learning-with-r">Deep Learning with R</a> is also a fatastic resource for those wishing to continue in this field.</p>
<p>======= ## Exercises</p>
<p>Solutions to exercises can be found in appendix <a href="solutions-nnet.html#solutions-nnet">6</a>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-angermueller2016deep">
<p>Angermueller, Tanel Pärnamaa, Christof, and Oliver Stegle. 2016. “Deep Learning for Computational Biology.” <em>Molecular Systems Biology</em> 12 (7): 878.</p>
</div>
<div id="ref-von2021democratising">
<p>Chamier, Lucas von, Romain F Laine, Johanna Jukkala, Christoph Spahn, Daniel Krentzel, Elias Nehme, Martina Lerche, et al. 2021. “Democratising Deep Learning for Microscopy with Zerocostdl4mic.” <em>Nature Communications</em> 12 (1). Nature Publishing Group: 1–18.</p>
</div>
<div id="ref-gomez2018automatic">
<p>Gómez-Bombarelli, Rafael, Jennifer N Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Alán Aspuru-Guzik. 2018. “Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules.” <em>ACS Central Science</em> 4 (2). ACS Publications: 268–76.</p>
</div>
<div id="ref-jumper2021highly">
<p>Jumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. “Highly Accurate Protein Structure Prediction with Alphafold.” <em>Nature</em> 596 (7873). Nature Publishing Group: 583–89.</p>
</div>
<div id="ref-Mohammad2019deep">
<p>Mohammad Lotfollahi, Fabian J. Theis, F. Alexander Wolf. 2019. “ScGen Predicts Single-Cell Perturbation Responses.” <em>Nat. Methods</em> 16 (8): 715–21.</p>
</div>
<div id="ref-Prabhu2020">
<p>Prabhu, Vinay Uday, and Abeba Birhane. 2020. “Large Image Datasets: A Pyrrhic Win for Computer Vision?” <em>CoRR</em> abs/2006.16923. <a href="https://arxiv.org/abs/2006.16923" class="uri">https://arxiv.org/abs/2006.16923</a>.</p>
</div>
<div id="ref-rampavsek2019dr">
<p>Rampášek, Ladislav, Daniel Hidru, Petr Smirnov, Benjamin Haibe-Kains, and Anna Goldenberg. 2019. “Dr. Vae: Improving Drug Response Prediction via Modeling of Drug Perturbation Effects.” <em>Bioinformatics</em> 35 (19). Oxford University Press: 3743–51.</p>
</div>
<div id="ref-tang2022sequential">
<p>Tang, Walfred WC, Aracely Castillo-Venzor, Wolfram H Gruhn, Toshihiro Kobayashi, Christopher A Penfold, Michael D Morgan, Dawei Sun, Naoko Irie, and M Azim Surani. 2022. “Sequential Enhancer State Remodelling Defines Human Germline Competence and Specification.” <em>Nature Cell Biology</em> 24 (4). Nature Publishing Group: 448–60.</p>
</div>
<div id="ref-zhang2022assessing">
<p>Zhang, Shuangquan, Anjun Ma, Jing Zhao, Dong Xu, Qin Ma, and Yan Wang. 2022. “Assessing Deep Learning Methods in Cis-Regulatory Motif Finding Based on Genomic Sequencing Data.” <em>Briefings in Bioinformatics</em> 23 (1). Oxford University Press: bbab374.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions-logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
